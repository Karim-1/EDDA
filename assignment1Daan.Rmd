---
title: "assignment1"
output: html_document
---

```{r setup, include=FALSE}
options(digits=3)
knitr::opts_chunk$set(echo = TRUE)
```

The data set birthweight.txt contains the birthweights of 188 newborn babies. We are interested in finding the underlying (population) mean μ of birthweights.

a) Check normality of the data. Compute a point estimate for μ. Derive, assuming normality (irrespective of your conclusion about normality od the data), a bounded 90% confidence interval for μ.

```{r echo=FALSE}
birth = read.table("birthweight.txt",header=TRUE)
birth$birthweight
mean(birth$birthweight)

shapiro.test(birth$birthweight)[2]
```

b) An expert claims that the mean birthweight is bigger than 2800, verify this claim by using a t-test. What is the outcome of the test if you take α = 0.1? And other values of α?

```{r}
alpha=0.1
t.test(birth$birthweight,mu=2800,alt="l",conf.level = 1-alpha)

alpha=0.05
t.test(birth$birthweight,mu=2800,alt="l",conf.level = 1-alpha)

alpha=0.01
t.test(birth$birthweight,mu=2800,alt="l",conf.level = 1-alpha)
```

c) In the R-output of the test from b), also a confidence interval is given, but why is it different from the confidence interval found in a) and why is it one-sided?
1 sided because you check if it is greater than mu and not both lower and greater.

Different because ... The confidence interval is one-sided because we only look if the mu is greater than 2800.


Exercise 2
We study the power function of the two-sample t-test (see Section 1.9 of Assignment 0). For n=m=30, mu=180, nu=175 and sd=5, generate 1000 samples x=rnorm(n,mu,sd) and y=rnorm(m,nu,sd), and record the 1000 p-values for testing H0: mu=nu. You can evaluate the power (at point nu=175) of this t-test as fraction of p-values that are smaller than 0.05.
```{r}
n=m=30
mu=180
nu=175
sd=5

B=1000
p=numeric(B)
for (b in 1:B) {
  x=rnorm(n,mu,sd);
  y=rnorm(m,nu,sd);
  p[b]=t.test(x,y,var.equal = TRUE)[[3]]}
a <- table(p)
length(a[names(a)<0.05])/length(a)
```

a) Set n=m=30, mu=180 and sd=5. Calculate now the power of the t-test for every value of nu in the grid seq(175,185,by=0.25). Plot the power as a function of nu.
```{r}
n=m=30
mu=180
nus=seq(175,185,by=0.25)
sd=5

powers = numeric(length(nus))

B=1000
p=numeric(B)
for (i in 1:length(nus)) {
  nu = nus[i]
  for (b in 1:B) {
    x=rnorm(n,mu,sd);
    y=rnorm(m,nu,sd);
    p[b]=t.test(x,y,var.equal = TRUE)[[3]]}
  a <- table(p)
  powers[i] = length(a[names(a)<0.05])/length(a)
} 
powers_a = powers
nus_a = nus

plot1 = plot(nus_a, powers_a)
```
b) Set n=m=100, mu=180 and sd=5. Repeat the preceding exercise. Add the plot to the preceding plot.
```{r}
n=m=100
mu=180
nus=seq(175,185,by=0.25)
sd=5

powers = numeric(length(nus))

B=1000
p=numeric(B)
for (i in 1:length(nus)) {
  nu = nus[i]
  for (b in 1:B) {
    x=rnorm(n,mu,sd);
    y=rnorm(m,nu,sd);
    p[b]=t.test(x,y,var.equal = TRUE)[[3]]}
  a <- table(p)
  powers[i] = length(a[names(a)<0.05])/length(a)
} 
powers_b = powers
nus_b = nus

plot2 = plot(nus, powers)
```

c) Set n=m=30, mu=180 and sd=15. Repeat the preceding exercise.
```{r, figures-side, fig.show="hold", out.width="50%"}
n=m=30
mu=180
nus=seq(175,185,by=0.25)
sd=15

powers = numeric(length(nus))

B=1000
p=numeric(B)
for (i in 1:length(nus)) {
  nu = nus[i]
  for (b in 1:B) {
    x=rnorm(n,mu,sd);
    y=rnorm(m,nu,sd);
    p[b]=t.test(x,y,var.equal = TRUE)[[3]]}
  a <- table(p)
  powers[i] = length(a[names(a)<0.05])/length(a)
} 
powers_c = powers
nus_c = nus
```

```{r}
par(mfrow=c(2,2))
plot(nus_a, powers_a, main="2a", xlab="nu", ylab="power")
plot(nus_b, powers_b, main="2b", xlab="nu", ylab="power")
plot(nus_c, powers_c, main="2c", xlab="nu", ylab="power")
```
d) Explain your findings.


Exercise 5. Chick weights
The dataset chickwts is a data frame included in the standard R installation, to view it, type chickwts at the R prompt. This data frame contains 71 observations on newly-hatched chicks which were randomly allocated among six groups. Each group was given a different feed supplement for six weeks, after which their weight (in grams) was measured. The data frame consists of a numeric column giving the weights, and a factor column giving the name of the feed supplement.

a) Test whether the distributions of the chicken weights for meatmeal and sunflower groups are different by performing three tests: the two samples t-test (argue whether the data are paired or not), the Mann-Whitney test and the Kolmogorov-Smirnov test. Comment on your findings.
```{r}
chickwts$feed
sun = chickwts[chickwts$feed == "sunflower",]
meat = chickwts[chickwts$feed == "meatmeal",]
sun$weight; meat$weight

t.test(sun$weight,meat$weight)
wilcox.test(sun$weight,meat$weight)

hist(sun$weight)
hist(meat$weight)

ks.test(sun$weight,meat$weight)
```
Welch two sample t-test p-value: 0.04
Mann-Whitney test p-value: 0.07
Kolmogorov-Smirnov test p-value: 0.1

b) Conduct a one-way ANOVA to determine whether the type of feed supplement has an effect on the weight of the chicks. Give the estimated chick weights for each of the six feed supplements. What is the best feed supplement?
```{r}
chickwts
sun = chickwts[chickwts$feed == "sunflower",]$weight
meat = chickwts[chickwts$feed == "meatmeal",]$weight
horse = chickwts[chickwts$feed == "horsebean",]$weight
linseed = chickwts[chickwts$feed == "linseed",]$weight
soy = chickwts[chickwts$feed == "soybean",]$weight
cas = chickwts[chickwts$feed == "casein",]$weight
sun; meat; horse; linseed; soy; cas



```

c) Check the ANOVA model assumptions by using relevant diagnostic tools.

d) Does the Kruskal-Wallis test arrive at the same conclusion about the effect of feed supplement as the test in b)? Explain possible differences between conclusions of the Kruskal-Wallis and ANOVA tests.

