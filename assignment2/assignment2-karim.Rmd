---
title: "assignment2-karim"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(digits=3)
```

Daan Moll (VU: 2559766 / UvA: 11929332)
Ramon Bussing (VU: 2687261 / UvA: 10719482)
Karim Semin (VU: ksn222 / UvA: 11285990)

Group number: 49


Stochastic models for word counts are used in quantitative studies on literary styles. Statistical analysis of the counts can, for example, be used to solve controversies about true authorships. Another example is the analysis of word frequencies in relation to Jane Austen’s novel Sanditon. At the time Austen died, this novel was only partly completed. Austen, however, had made a summary for the remaining part. An admirer of Austen’s work finished the novel, imitating Austen’s style as much as possible. The file austen.txt contains counts of different words in some of Austen’s novels: chapters 1 and 3 of Sense and Sensibility (stored in the Sense column), chapters 1, 2 and 3 of Emma (column Emma), chapters 1 and 6 of Sanditon (both written by Austen herself, column Sand1) and chapters 12 and 24 of Sanditon (both written by the admirer, Sand2).
**4a)** Discuss whether a contingency table test for independence or for homogeneity is most appropriate here.
In order to analyze the word count of the chapters of the finished novel, we look to see whether the word count in the chapter written by her admirer are consistent with the word count written by Jane Austen's herself. We therefore look to see whether the proportion of word counts are consistent Austin's original work and the finished work by her admirer. Because of this, a contingency table for homogeneity is appropriate, to check whether the distribution of word counts are equal between the original work of Austen (Sense, Emma, Sand1) and her admirer (Sand2).

**4b)** Using the given data set, investigate whether Austen herself was consistent in her different novels.
Where are the main inconsistencies?

To investigate whether Austen's work was consistent in her different novels, we regard the Sense, Emma and Sand1 column of the dataset. We then calculate the sum of each row and column and the total word count. With these sums of the rows and columns and the total word count, we can calculate the expected value for each cell. These computations are done by the build in chisq.test function of R. The result of the Chi-squared test can be observed below.

```{r}
wordcounts = read.table("austen.txt", header=TRUE)
austen = subset(austen, select = c('Sense', 'Emma', 'Sand1'))
z=chisq.test(austen)
z
```
The p-value is .3. From this we can conclude that the word counts for each combination of word and book chapters are not independent of each other. This is to be expected, as these chapters are all written by the same Author. To consider inconsistencies in the rows and columns, we observe the residuals of the cells (the square root contribution of each cell to the chi-square statistic.) These values give an indication of how much cell values differ from the expected values under $H_0$.

```{r}
z$residuals
```
From the table, inconsistencies with regards to the expected wordcounts can be observed. The main inconsistencies are listed below:
- The word 'a' was used more often in Sanditon than in Sense and Sensibility book.
- The word 'without' was used much less in Emma as opposed to the other two books.
- The word 'that' was used less in Sanditon than in her other two books.


**4c)** Was the admirer successful in imitating Austen’s style? Perform a test including all data. If he was
not successful, where are the differences?

Next, we check whether the admirer successful in imitating Austen’s style. We do this by adding back the column with the admirer's word counts and once again performing a chi-square test.
```{r}
z1=chisq.test(wordcounts)
z1
```
The p-value is now smaller than .001, meaning that after adding back the Sand2 column, the word counts may be considered independent on each other. We can investigate where these differences lay if we once again investigate the contribution of each to the chi-square test statistic with the residuals.

```{r}
z1$residuals
```

From the table we can gather that these differences lay;
- The admirer uses the word 'an' much more often than Austen relatively.
- The admirer uses the word 'that' far less often than Austen relatively.
- The admirer uses the word 'with' more often than Austen relatively.
(In comparison to the expected word count under $H_0$.)



Daan's opdracht:
```{r}
students = read.table("search.txt",header=TRUE)
students
```
A researcher is interested in the time it takes a student to find a certain product on the internet using a search engine. There are three different types of interfaces with the search engine and especially the effect of these interfaces is of importance. There are five different types of students, indicating their level of computer skill (the lower the value of this indicator, the better the computer skill of the corresponding student). Fifteen students are selected; three from each group with a certain level of computer skill. The data is given in the file search.txt. Assume that the experiment was run according to a randomized block design which you make in a). (Beware that the levels of the factors are coded by numbers.)
**2a** 
randomised block design
```{r echo=FALSE}
# lower the skill value the better the computer skill
# randomized block design
# numerical outcome Y
# treatment, factor of interest with I levels (type of interface)
# block, factor that is not of interest, B, (computer skill)

# purpose is to find dependence of Y on I
# block variable is thought to be of influence.
# our problem is same as example lec5slide23
I = 3
B = 5
N = 1
for (b in 1:B) {
  print(sample(1:(N*I)))
}
# maar hoe dat 15 studenten erin worden vernoemd?

# example output: 2 3 1
# means: assign student 2 to treatment 3, student 3 to treatment 1 and student 1 to treatment 2

# unit is that that receives the treatment, so student
```
dus skill level 1
student 3 interface 1
student 1 interface 2
student 2 interface 3

de 3 studenten van skill level 1:
3 1 2

de 3 studenten van skill 2 level 2:
1 2 3

**2b**
Test the null hypothesis that the search time is the same for all interfaces. 

What type of interface does require the longest search time? For which combination of skill level and type of interface is the search time the shortest? Estimate the time it takes a typical user of skill level 3 to find the product on the website if the website uses interface 3.
```{r message=FALSE, warning=FALSE}
students$interface = as.factor(students$interface)
students$skill = as.factor(students$skill)
attach(students)

par(mfrow=c(1,2))

boxplot(time~interface)
boxplot(time~skill)

interaction.plot(interface,skill,time)

studentslm = lm(time~interface*skill)
# anova(studentsaov2)
```
--------- If assume normal then this:
p value for interface:skill is 0.340. So there is no evidence for interaction. 


------- If assume not normal then this:
The krukal willis test was used because of questionable normality. The KW test returns a p-value of 0.1 which is greater than 0.05 and thus we accept the H0 hypothesis. This means there is no significant difference between interfaces.
// nog ff checken

What type of interface requires the longest search time?
```{r}
inter1 = mean(students$time[interface==1])
inter2 = mean(students$time[interface==2])
inter3 = mean(students$time[interface==3])
which.max(c(inter1, inter2, inter3))
```
interface 3 has the highest mean search time.

Which combination of skill and interface is search time shortest
```{r}
students[which.min(students$time),]
```

estimate time it takes for skill level 3 to find product with interface 3
So treatment(I) = 3, block(B)=3

Found on wiki:
estimate for B_j: barY_j - barY with barY_j


```{r}
summary(studentslm)
```

**2c**
check the model assumptions by using relevant diagnostic tools
```{r}
qqnorm(time)
shapiro.test(time)
# normality is questionable, so kruskall willis
boxplot(time)
stripchart(time~interface, vertical = TRUE)
```

**2d**
Perform the Friedman test to test whether ther is an effect of interface
```{r}
interaction.plot(students$interface, students$skill, students$time)
friedman.test(time,interface,skill,data=students)