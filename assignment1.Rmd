---
title: "Assignment 1 \n Experimental Design and Data Analysis"
output: 
  html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(digits=3)
```

Daan Moll (VU: 2559766 / UvA: 11929332)
Ramon Bussing (VU: 2687261 / UvA: 10719482)
Karim Semin (VU: ksn222 / UvA: 11285990)

Group number: 49


For all exercises, an $\alpha$ significance level of .05 is used, unless stated otherwise.

## Exercise 1
First, we check the normality of the data. This is done with a Quantile-Quantile plot (QQ-plot). A QQ-plot for normality has on the x-axis the theoretical quantiles corresponding with a normal distribution and on the y-axis the sample quantiles. When the sample values (the dots) follow the given linear line, the quantiles of the data correspond with the quantiles of the normal distribution allowing us to confirm normality of the sample. We observe the following QQ-plot:
```{r}
birth= read.table("birthweight.txt",header=TRUE)
birthweight = birth$birthweight
qqnorm(birthweight)
```
The dots in the plot seem aligned relatively straight, implying that the data is normally distributed. To be sure of this conclusion, the normality of the data is also tested with the Shapiro-Wilk test. When using the Shapiro-Wilk test for large datasets it has a high chance of returning a type one error. This is caused by small deviations from the hypothesis which are actually too small to be of any significance. This error will not occur in the case of our dataset, as it is relatively small (n=188). 

```{r}
shapiro.test(birthweight)[2]
```

The Shapiro wilk test gives us a non-significant p-value (p = .9). This implies that h0 is not rejected, implying that the data is normally distributed).

Next, a point estimate for μ is derived with a 90% bounded confidence interval.

```{r}
cat('mean =', mean(birthweight))
z_star_90 = qnorm(.95)
lower_bound = mean(birthweight) - z_star_90 * (sd(birthweight) / sqrt(length(birthweight)))
upper_bound = mean(birthweight) + z_star_90 * (sd(birthweight) / sqrt(length(birthweight)))

cat('\n90% confidence interval = [', lower_bound,',', upper_bound,']')
```
From the 90% confidence interval, it is expected that if the experiment was repeated endless times, in 90% of the experiments, the mean should be within our confidence interval.

b) Next, we test the alternative hypothesis that µ > 2800 with a t-test. Given that we want to investigate if the true mean birth weight is bigger than 2800, the corresponding H0 is that true mean is less or equal than 2800. This is done with help of a t-test.
```{r}
t.test(birthweight, alternative = "g", mu = 2800)[3]

cat('with confidence level = .1, CI =\n[',t.test(birthweight, conf.level = 0.1, alternative = "g", mu = 2800)[[4]][1],',',t.test(birthweight, conf.level = 0.1, alternative = "g", mu = 2800)[[4]][2],']')
cat('\n')

cat('\nwith confidence level = .01, CI =\n[',t.test(birthweight, conf.level = 0.01, alternative = "g", mu = 2800)[[4]][1],',',t.test(birthweight, conf.level = 0.01, alternative = "g", mu = 2800)[[4]][2],']')
cat('\n')
```

The result is statistically significant when p is equal or less than alpha. Given that the p-value from that t-test is 0.01, we conclude that we have evidence for a true mean greater than 2800 if our alpha is 0.01 or higher. So for the alpha of 0.1 we conclude that we found significant evidence for a true mean bigger than 2800. Since our Ha is about the true mean being bigger than a value, the corresponding confidence interval has a lower bound with specific value and infinite for the upper bound. When alpha becomes lower, the confidence interval becomes smaller, resulting in our case in a higher lower bound.

c) The R-output from b) is different from a), as we are using a different test statistic (µ). The confidence interval is one-sided, because the alternative hypothesis is that the mean weight is 'greater than' a certain value, as opposed to the alternative hypothesis that the true mean lays outside of our confidence interval.


## Exercise 2
We study the power function of the two-sample t-test (see Section 1.9 of Assignment 0). For n=m=30, mu=180, nu=175 and sd=5, generate 1000 samples x=rnorm(n,mu,sd) and y=rnorm(m,nu,sd), and record the 1000 p-values for testing H0: mu=nu. You can evaluate the power (at point nu=175) of this t-test as fraction of p-values that are smaller than 0.05.
```{r}
set.seed(10)
n=m=30
mu=180
nu=175
sd=5

B=1000
p=numeric(B)
for (b in 1:B) {
  x=rnorm(n,mu,sd);
  y=rnorm(m,nu,sd);
  p[b]=t.test(x,y,var.equal = TRUE)[[3]]}
a <- table(p)
cat('proportion of p-values < .05:\n', length(a[names(a)<0.05])/length(a))
```

From the 1000 generated samples a fraction of 0.558 samples have p-values lower than 0.05.

a) We first calculate the t-test with n=m=30, mu=180 and sd=5 for every value of nu in the grid seq(175,185,by=0.25).
```{r}
n=m=30
mu=180
nus=seq(175,185,by=0.25)
sd=5

powers = numeric(length(nus))

B=1000
p=numeric(B)
for (i in 1:length(nus)) {
  nu = nus[i]
  for (b in 1:B) {
    x=rnorm(n,mu,sd);
    y=rnorm(m,nu,sd);
    p[b]=t.test(x,y,var.equal = TRUE)[[3]]}
  a <- table(p)
  powers[i] = length(a[names(a)<0.05])/length(a)
} 
powers_a = powers
nus_a = nus

```


b) We repeat step a), with n=m=100, mu=180 and sd=5.
```{r}
n=m=100
mu=180
nus=seq(175,185,by=0.25)
sd=5

powers = numeric(length(nus))

B=1000
p=numeric(B)
for (i in 1:length(nus)) {
  nu = nus[i]
  for (b in 1:B) {
    x=rnorm(n,mu,sd);
    y=rnorm(m,nu,sd);
    p[b]=t.test(x,y,var.equal = TRUE)[[3]]}
  a <- table(p)
  powers[i] = length(a[names(a)<0.05])/length(a)
} 
powers_b = powers
nus_b = nus
```

c) Step a) is once again repeated with n=m=30, mu=180 and sd=15.
```{r, figures-side, fig.show="hold", out.width="50%"}
n=m=30
mu=180
nus=seq(175,185,by=0.25)
sd=15

powers = numeric(length(nus))

B=1000
p=numeric(B)
for (i in 1:length(nus)) {
  nu = nus[i]
  for (b in 1:B) {
    x=rnorm(n,mu,sd);
    y=rnorm(m,nu,sd);
    p[b]=t.test(x,y,var.equal = TRUE)[[3]]}
  a <- table(p)
  powers[i] = length(a[names(a)<0.05])/length(a)
} 
powers_c = powers
nus_c = nus
```

If we plot the respective powers of the t-tests from a), b) and c), we observe the following plot.
```{r}
plot(nus_a, powers_a, main="Power as a function of nu", xlab="nu", ylab="fraction of power < 0.05", pch=20, col="blue")
lines(nus_a, powers_a, xlab="nu", pch=20, col="blue")
points(nus_b, powers_b, xlab="nu", pch=20, col="red")
lines(nus_b, powers_b, xlab="nu", pch=20, col="red")
points(nus_c, powers_c, xlab="nu", pch=20, col="green")
lines(nus_c, powers_c, xlab="nu", pch=20, col="green")
legend(184, 0.5, legend=c("a", "b", "c"), col=c("blue", "red", "green"), lty=1, cex=0.8)
```


d) On the y-axis we observe the fraction of power < .05. When the fraction of power <.05 is high, we are less certain about which hypothesis to chose. We are more certain to accept H0 when the mu is closer to 180, and we get more certain about accepting Ha when we get further away from 180. When nu is close to 180, we're not certain which hypothesis to accept due to the similarity in likelihood between H0 and Ha. This explains the curve with the two symmetrical peaks next to 180. When the standard deviation is higher (question c compared to a), the range of uncertainty gets larger, or in other words: The area under the line get larger. This is expected, because the t-test compares the means of the groups. With an increase in spread/standard deviation, the confidence interval becomes larger, giving us less power and thus a larger range of uncertainty about which hypothesis to choose. When we take more samples (question b compared to a) the power increases as the tails of the t-distribution get thinner, hence the smaller range of uncertainty for b compared to a.


## Exercise 3
a) If we plot the telephone.txt data set, we observe the following plot:
```{r echo=FALSE}
tel_data = read.table("telephone.txt",header=TRUE)
```
If we observe the data, we see several participants that have a first month bill of €0. This does not seem plausible, as the company probably would not give out subscriptions for free. Therefore, we trim the data of zero-values.

```{r}
# remove 0-values
corrected_tel_data = tel_data[apply(tel_data, 1, function(row) all(row !=0 )), ]

# plot histograms
par(mfrow=c(1,2))
hist(tel_data$Bills, xlab = "First month bills (€)", main = "data before correction", ylim = c(0,55))
hist(corrected_tel_data, xlab = "First month bills (€)", main = "data after correction", ylim = c(0,55))

# plot boxplots
par(mfrow=c(1,2))
boxplot(tel_data$Bills, ylab = "€", main = "data before correction")
boxplot(corrected_tel_data, ylab = "€", main = "data after correction")
```

We now see that the first bin (containing €0-€10 subscriptions) in the histogram contains a lower frequency due to the removal of zero-values. Based on the boxplots, we see that the the median of the data is relatively low with regards to the total range of subscription-prices. This implies that a larger part of participants have relatively low phone bills. Therefore, we might advice the marketing manager to focus on low-price subscriptions. 


b) We then test wether the data stems from an exponential distribution with $\lambda$ from [.01, .1] .by bootstrapping with the median as the test statistic. 

```{r}
lambdas = seq(.01, .1, .0005)
t = median(corrected_tel_data)
B=1000
tstar=numeric(B)
n=length(corrected_tel_data)
p_values = c()

for(lamb in lambdas){
  for (i in 1:B){
    xstar=rexp(n, lamb)
    tstar[i]=median(xstar)}
    
  p_left=sum(tstar<t)/B
  p_right=sum(tstar>t)/B
  p = 2*min(p_left,p_right)
  p_values = c(p_values, p)
}

plot(lambdas, p_values, main = "P-values for lambda = [.01, 1]", xlab="lambda", ylab="p-values", pch=20)

max_index_lamb = which.max(p_values)
estimated_lamb= lambdas[max_index_lamb]

cat("p-value for lambda =", estimated_lamb,"-->", max(p_values))
```

In the graph, we find a peak for $\lambda = .024$ with $p = .97$  This implies that the distribution of the data comes from an exponential distribution with $\lambda = .024$. 


c) Next, we construct a 95% bootstrap confidence interval for the population median of the sample. This is done by iteratively resampling sub-datasets from the original dataset with replacement. We do this for a total of 5000 times, to get stable results according to the law of large numbers.

```{r}
set.seed(10)
B=5000
Tstar=numeric(B)
T1 = median(corrected_tel_data)

for(i in 1:B) {
  Xstar=sample(corrected_tel_data,replace=TRUE)
  Tstar[i]=median(Xstar) }
  Tstar025=quantile(Tstar,0.025)
  Tstar975=quantile(Tstar,0.975)
  
population_median = mean(Tstar)
cat('95% CI = [',2*T1-Tstar975, '-',2*T1-Tstar025,'] with population median:', population_median)
```
The 95% bootstrap confidence interval for the population median of the telephone data is [16.4, 37.7] around the population median (28.7).


d) Assuming X1 , . . . Xn ∼ Exp(λ) and using the central limit theorem for the sample mean, estimate $\lambda$ and construct again a 95% confidence interval for the population median. Comment on your findings.

We once again use the bootstrapping method to sample from the dataset. For each sample, the mean is retrieved and stored in a vector. 

```{r}
B=5000
Tstar=numeric(B)

for(i in 1:B) {
  Xstar=sample(corrected_tel_data,replace=TRUE)
  Tstar[i]=mean(Xstar) 
}
```


In order to check whether the central limit theorem applies, the data is checked for normality with a QQ plot. 
```{r}
qqnorm(Tstar)
```
Here, it can be observed that all the datapoints lay on a straight line. Therefore, normality may be assumed and thus the central limit theorem applies. 

Therefore, the CLT applies. We can then obtain an estimate for $\lambda$ with:
$\lambda = \frac{1}{\mu}$

Giving us an estimate of:
```{r}
est_lamb = 1/(mean(Tstar))
cat('Estimated lambda',est_lamb, '(based on the sample means)')
```

We then again use the bootstrapping method to generate a 95% confidence interval. Here, the samples are retrieved from the exponential distrubution with the newly estimated lambda value (.022). 

```{r}
set.seed(10)
Tstar=numeric(B)

for(i in 1:B) {
  Xstar=rexp(n, est_lamb)
  Tstar[i]=median(Xstar) }

Tstar025=quantile(Tstar,0.025)
Tstar975=quantile(Tstar,0.975)

exponential_median = mean(Tstar)
cat('95% CI = [',2*exponential_median-Tstar975, '-',2*exponential_median-Tstar025,'] with population median:', exponential_median)
```

We observe a 95% confidence interval of [24.8 - 37.7] with a mean median of 31.7. 


e) Using an appropriate test, test the null hypothesis that the median bill is bigger or equal to 40 euro against the alternative that the median bill is smaller than 40 euro. Next, design and perform a test
to check whether the fraction of the bills less than 10 euro is less than 25%.


In order to test the null hypothesis that the median bill is bigger or equal to 40 euro's against the alternative that the median bill is smaller than 40 euro's, we use the Wilcoxon signed rank test. This test assumes that the data is symmetrically distributed around the median. This can be reviewed by observing the histogram in 3a). From the histogram we can gather that the data is more or less distributed evenly around the median (28.9) therefore we can now perform the Wilcoxon test.

```{r}
wilcox.test(corrected_tel_data, mu=40, alternative="less")
```

We get a p-value of 1, implying that we should not reject H0. 

Next, we test the alternative hypothesis that the fraction of the bills less than 10 euro is less than 25%. We can do this by with the binomial test. This test gives the probility of observing a certain expected distribution of observations (25% of bills is less than 10 euro's, in our case). The binomial test assumes that data samples are independent, which is the case in our experiment. 

```{r}
set.seed(10)
B=5000
Tstar=numeric(B)
T1 = 10

for(i in 1:B) {
  Xstar=sample(corrected_tel_data,replace=TRUE)
  Tstar[i]=sum(Xstar < T1) / length(Xstar)
  }
Tstar95=quantile(Tstar,0.95)
Tstar95

under10 = sum(corrected_tel_data < 10)
over10 = sum(corrected_tel_data >= 10)
binom.test(c(under10, over10), p = .25, alternative = "less")[3]

```

The binomial test gives us a p-value of .283, meaning that we should not reject our h0 hypothesis. This implies that the hypothesis that the fraction of the bills less than 10 euro is less than 25% should not be accepted. 


## Exercise 4
To study the effect of energy drink, a sample of 24 high school pupils were randomized to drinking either a
softdrink or an energy drink after running for 60 meters. After half an hour they were asked to run again.
For both sprints they were asked to sprint as fast they could, and the sprinting time was measured. The
data is given in the file run.txt [Courtesy class 5E, Stedelijk Gymnasium Leiden, 2010.].

```{r echo=FALSE}
run = read.table("run.txt",header=TRUE)
lemo = subset(run, drink == "lemo")
energy = subset(run, drink == "energy")
```


a) Firstly, we will disregard the type of drink and test whether the run-times before and after the drink are correlated. 

```{r}
plot(run$before, run$after, xlab="Run time before drink", ylab="Run time after drink")
cor.test(run$before, run$after,  method = "pearson")[3]
```

Since Pearson's product-moment correlation p < 0.05, we can state that we found significant evidence that a true correlation exists.

b) Next, we check whether there is a difference in speed for the two running tasks. We first check the data for normality again. In order to compare these two groups, we will use a t-test. The t-test will be used to do this. Since the t-test assumes normally distributed data, we test the data for normality again first. As in exercise 1a), this is done with QQ-plots and the Shapiro-Wilk test.
```{r}
# check normality for lemonade group
qqnorm(lemo$before)
qqnorm(lemo$after)
shapiro.test(lemo$before)
shapiro.test(lemo$after)

# check normality for energy drink group
qqnorm(energy$before)
qqnorm(energy$after)
shapiro.test(energy$before)
shapiro.test(energy$after)
```

The QQ-plots seem relatively normal. Moreover, the Shapiro-Wilk test gives us non-significant p-values (>.05). Therefore, the assumption for normality is met.

This allows us to compare the run times before and after the drink with a t-test.
```{r}
t.test(lemo$before, lemo$after, paired = TRUE, var.equal = FALSE)[3]
t.test(energy$before, energy$after, paired = TRUE, var.equal = FALSE)[3]
```
For both drinks, a non-significant p-value is found (p > 0.05). Therefore, the null-hypothesis is not rejected. This implies that no evidence for a difference between before and after drink run times for both the energy and the lemonade group is found.


c) We then check whether we find a time difference between the two running tasks and if these time differences are affected by the type of drink. To do this, we first compute the time differences before and after the drink. Next, we compare the differences for both group.
```{r}
lemo_diff = lemo$before - lemo$after
energy_diff = energy$before - energy$after

t.test(lemo_diff, energy_diff, paired = FALSE)[3]
```

We once again find a non-significant p-value for the t-test (.159). Therefore, the null-hypothesis is not rejected, implying that there is no differences in run-time are found for before and after consuming the drink for both drinks. 

d) A plausible objection against the experiment in b) may be that the experiment takes the before drink run times as the control group and the after drink run times for the experiment group. The aim of the experiment was to investigate the difference between energy drink an limo on running times. When investigating a difference between before and after drinking, the difference between drinks is not investigated.

In addition to this, the research question states that the increase in running times after drinking energy and control group limo needs to be researched. However, only the running times after drinking need to be taken into consideration, because it is assumed that participants run slower on the 'after' run due to fatigue of the first run. This effect works against what we want to investigate. This very same point of criticism also applies to question c, since that question asks for the time difference between the before and after group.


## Exercise 5. Chick weights
The dataset chickwts is a data frame included in the standard R installation, to view it, type chickwts at the R prompt. This data frame contains 71 observations on newly-hatched chicks which were randomly allocated among six groups. Each group was given a different feed supplement for six weeks, after which their weight (in grams) was measured. The data frame consists of a numeric column giving the weights, and a factor column giving the name of the feed supplement.

a) For the next statistical tests, the dataset 'chickwts' is used. We test whether the chicken weights for meatmeal and sunflower groups are different by performing three tests: the two samples t-test (argue whether the data are paired or not), the Mann-Whitney test and the Kolmogorov-Smirnov test.
```{r}
sun = chickwts[chickwts$feed == "sunflower",]$weight
meat = chickwts[chickwts$feed == "meatmeal",]$weight

# check for normality
shapiro.test(sun)
shapiro.test(meat)

# compare groups
cat('two samples t-test p-value:\n',t.test(sun,meat, paired = FALSE)[[3]])
cat('\n\nMann-Whitney test p-value:\n',wilcox.test(sun,meat)[[3]])
cat('\n\nKolmogorov-Smirnov test p-value:\n',ks.test(sun,meat)[[2]])
```

Since the chickens in both groups are unique, the data is not paired. Paired data would be the case if we would measure the same chicken twice. The Welch's T-test gives a p-value of .044, therefore, we would reject H0 according to alpha=0.05, meaning that we have reason to assume that the true mean weights of the chickens with sunflower and meatmeal are different. 

The Mann-Whitney test has a p > 0.05, therefore we can not conclude from this test that the populations are unequal. This test bases its p-value on the discrepancy between the mean ranks of ordered groups.

The KS-test too has a p-value >.05, therefore we cannot conclude that the populations are unequal. This test bases its p-value on the largest discrepancy between two cumulative density frequency distributions from the two samples. 

We find discrepancy between p-values for the parametric and non-parametric tests. Given that the Mann-Whitney and KS test are non-parametric, generally speaking, these tests have less power than the parametric t-test, we therefore expect these p-values to be higher than the t-test. Since the t-test has more power than the non-parametric tests, we reject h0, and thus find significant evidence for a true difference between the means of the groups.


b) Next, a one-way ANOVA is performed to determine whether the type of feed supplement has an effect on the weight of the chicks. Therefore, the estimated chick weights for each of the six feed supplements is calculated.
```{r}
chickwts = chickwts

boxplot(weight ~ feed, data=chickwts,las=2)

chickaov = lm(weight ~ feed, data = chickwts)

cat('ANOVA p-value:\n', anova(chickaov)[[5]][1])
```
The ANOVA only tells us that at least one of all the tested groups are different from the rest, thus no conclusions about the best feed supplement can be made. In addition, "best" is undefined in the question, meaning that we don't know what best means for the researcher. Maybe chickens with less weight variance can be sold more easily and are thus the "best", but maybe the highest mean weight can be sold for the most money and is thus the best. We simply don't know, therefore we can't state which group is the best with only the information given.

c) We then check whether the assumptions for the ANOVA are met. We first check the assumption of equal variances by plotting the residauls against the fitted values.
```{r}
plot(chickaov, 1)
```
This plot does not show a relationship between the fitted values and the residuals, allowing us to conclude that the assumption for equality of variances is met.

Next, we test the assumption of normally distributed data. This is once again done with a QQ-plot and the Shapiro-Wilk test.
```{r}
plot(chickaov, 2)
shapiro.test(residuals(chickaov))
```
This plot shows that the measurements follow the diagonal dotted line, allowing us to conclude that the assumption for normality is met. This claim is supported by the Shapiro–Wilk test since its p-value is non-significant.


d) Does the Kruskal-Wallis test arrive at the same conclusion about the effect of feed supplement as the test in b)? Explain possible differences between conclusions of the Kruskal-Wallis and ANOVA tests.

The ANOVA gives a p-value that states the probability that the distributions of the data of three or more groups are equal. When the p-value is considered significant, we can conclude that the distribution of the data of at least one group is different from the others.
The Kruskal-Wallis test is also able to compare distributions, but than for two groups rather than three or more. In addition to this, the Kruskal-wallis test bases its p-value on the largest discrepancy between two cummulative density frequency distributions from the two samples rather than the means.




